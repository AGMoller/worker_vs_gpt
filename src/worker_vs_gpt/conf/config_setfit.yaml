batch_size: 8
lr_body: 1e-5
lr_head: 1e-5
num_iterations: 20 # Used in the paper (20)
num_epochs_body: 1 # 1 is used in paper
num_epochs_head: 20 # In their tutorial they use 50. Not clear how many they use in training. 
weight_decay: 2e-6
wandb_project: social-dim-setfit
wandb_entity: cocoons
ckpt: intfloat/e5-base
text_selection: h_text
experiment_type: aug # can be 'crowdsourced', 'aug', 'both'
sampling: proportional # can be proportional or balanced
augmentation_model: gpt-4 # can be gpt-3.5-turbo or gpt-4