{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ptitprince as pt\n",
    "from matplotlib import patches\n",
    "from matplotlib import lines\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "# disable warnings>\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute avg similarity for each base sample\n",
    "# similarities_avg_individual = {k: {} for k in labels}\n",
    "# for label, dict_with_similarities in data.items():\n",
    "#     for text in dict_with_similarities:\n",
    "#         list_similarities = [x[0] for x in dict_with_similarities[text]]\n",
    "#         similarities_avg_individual[label][text] = sum(list_similarities) / len(\n",
    "#             list_similarities\n",
    "#         )\n",
    "\n",
    "# # Compute avg similarity for each label\n",
    "# similarities_avg_label = {k: [] for k in labels}\n",
    "# similarities_list_label = {k: [] for k in labels}\n",
    "# for label, dict_with_similarities in similarities_avg_individual.items():\n",
    "#     for text, similarity in dict_with_similarities.items():\n",
    "#         similarities_avg_label[label].append(similarity)\n",
    "#         similarities_list_label[label].append(similarity)\n",
    "\n",
    "#     similarities_avg_label[label] = sum(similarities_avg_label[label]) / len(\n",
    "#         similarities_avg_label[label]\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot with all similarities for all files\n",
    "\n",
    "# Ten-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir() if file.startswith('ten-dim') and file.endswith('.json')]\n",
    "labels: List[str] = [\n",
    "            \"social_support\",\n",
    "            \"conflict\",\n",
    "            \"trust\",\n",
    "            \"neutral\",\n",
    "            \"fun\",\n",
    "            \"respect\",\n",
    "            \"knowledge\",\n",
    "            \"power\",\n",
    "            \"similarity_identity\",\n",
    "        ]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for filename in files:\n",
    "    data = pd.read_json(filename, orient='records')\n",
    "    name = \"_\".join( filename.split('_')[1:3])\n",
    "    data['dataset'] = name\n",
    "    data['label'] = data.target.apply(lambda x: labels[x])\n",
    "    data.rename(columns = {'pairwise_sim': 'inter-similarity', \"within_sim\" : 'intra-similarity', \n",
    "    \"augment_sbleu_group\" : 'self_bleu_group', \"augment_sbleu\" : 'self_bleu'}, inplace = True)\n",
    "    df_list.append(data)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "df = df[df.self_bleu_group > -1]\n",
    "\n",
    "#parse the classifcation reports in the folder classification_results, the files are csv files\n",
    "classification_reports = []\n",
    "for filename in os.listdir('./classification_results'):\n",
    "    if filename.endswith('.csv'):\n",
    "        cl = pd.read_csv(os.path.join('./classification_results', filename))\n",
    "        cl['dataset'] = \".\".join(filename.split('.')[:-1])\n",
    "        #convert label columns to long format\n",
    "        cl = pd.melt(cl[labels + [ 'metric', 'dataset']], id_vars=[ 'metric', 'dataset'], value_vars=labels, var_name='label', value_name='score')\n",
    "\n",
    "        #convert metric column to wide format\n",
    "        \n",
    "        classification_reports.append(cl)\n",
    "\n",
    "metrics_df = pd.concat(classification_reports)\n",
    "metrics_df = metrics_df.pivot(index=['dataset', 'label'], columns='metric', values='score')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle_value(data):\n",
    "    return data.iloc[int(len(data)/2)]\n",
    "\n",
    "#group df by dataset and label, then show the rows with the 10 highest similarity\n",
    "df_grouped_low = df.groupby(['dataset', 'label']).apply(lambda x: x.nsmallest(1, 'inter-similarity')).reset_index(drop=True)\n",
    "df_grouped_low['type'] = 'low'\n",
    "\n",
    "df_grouped_high = df.groupby(['dataset', 'label']).apply(lambda x: x.nlargest(1, 'inter-similarity')).reset_index(drop=True)\n",
    "df_grouped_high['type'] = 'high'\n",
    "\n",
    "df_grouped_med = df.groupby(['dataset', 'label']).apply(lambda x: get_middle_value(x.sort_values('inter-similarity'))).reset_index(drop=True)\n",
    "df_grouped_med['type'] = 'med'\n",
    "\n",
    "# inner join all three dataframes\n",
    "df_grouped = pd.merge(df_grouped_low, df_grouped_high, on=['dataset', 'label'], suffixes=('_low', '_high'))\n",
    "df_grouped = pd.merge(df_grouped, df_grouped_med, on=['dataset', 'label'], suffixes=('', '_med'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all three dataframes\n",
    "df_grouped_concat = pd.concat([df_grouped_low, df_grouped_high, df_grouped_med])\n",
    "#filter for datasets including balanced \n",
    "df_grouped_concat = df_grouped_concat[df_grouped_concat.dataset.str.contains('balanced')]\n",
    "\n",
    "df_grouped_concat = df_grouped_concat[['label', 'type', 'dataset', 'h_text', 'augmented_h_text']].reset_index(drop=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "#sort be label, type and dataset\n",
    "df_grouped_concat = df_grouped_concat.sort_values(['label', 'type', 'dataset']).reset_index(drop=True)\n",
    "#rename values in dataset column\n",
    "df_grouped_concat.dataset = df_grouped_concat.dataset.apply(lambda x: x.replace('balanced_gpt-3.5-turbo', 'ChatGPT').replace('balanced_gpt-4', 'GPT-4'))\n",
    "#rename values in type column\n",
    "df_grouped_concat.type = df_grouped_concat.type.apply(lambda x: x.replace('low', 'Low').replace('high', 'High').replace('med', 'Medium'))\n",
    "#rename values in label column\n",
    "df_grouped_concat.label = df_grouped_concat.label.apply(lambda x: x.replace('social_support', 'Social Support').replace('conflict', 'Conflict').replace('trust', 'Trust').replace('neutral', 'Neutral').replace('fun', 'Fun').replace('respect', 'Respect').replace('knowledge', 'Knowledge').replace('power', 'Power').replace('similarity_identity', 'Similarity/Identity'))\n",
    "#rename h_text column to Base\n",
    "df_grouped_concat.rename(columns={'h_text': 'Base'}, inplace=True)\n",
    "#rename augmented_h_text column to Augmented\n",
    "df_grouped_concat.rename(columns={'augmented_h_text': 'Augmented'}, inplace=True)\n",
    "#capital column names\n",
    "df_grouped_concat.columns = df_grouped_concat.columns.str.capitalize()\n",
    "#rename type column to Similarity\n",
    "df_grouped_concat.rename(columns={'Type': 'Similarity'}, inplace=True)\n",
    "\n",
    "print(df_grouped_concat.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby([ 'dataset']).agg({'self_bleu_group': ['mean', 'std'],\n",
    "                                      'inter-similarity': ['mean', 'std'],\n",
    "                                      'intra-similarity': ['mean', 'std'],\n",
    "                                        'self_bleu': ['mean', 'std']}\n",
    "                                      ).round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = df.groupby(['label', 'dataset']).agg({'self_bleu_group': ['mean', 'std'],\n",
    "                                      'inter-similarity': ['mean', 'std'],\n",
    "                                      'intra-similarity': ['mean', 'std'],\n",
    "                                        'self_bleu': ['mean', 'std']}\n",
    "                                      )\n",
    "#reset columns\n",
    "mean_data.columns = mean_data.columns.map('_'.join).str.strip('_')\n",
    "mean_data.reset_index(inplace=True)\n",
    "\n",
    "mean_data = mean_data.merge(metrics_df, on=['dataset', 'label'], how='left')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-similarity vs Intra-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 subplots one for each dataset in mean_data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "for i, (dataset, data) in enumerate(mean_data.groupby('dataset')):\n",
    "    ax = axes[i//2, i%2]\n",
    "    sns.scatterplot(data=data, x='inter-similarity_mean', y='intra-similarity_mean', hue='label', ax=ax)\n",
    "    ax.set_title(dataset)\n",
    "    ax.set_xlabel('inter-similarity')\n",
    "    ax.set_ylabel('intra-similarity')\n",
    "        #make only a single legend\n",
    "    if i == 0:\n",
    "        axes[i//2, i%2].legend()\n",
    "    else:\n",
    "        axes[i//2, i%2].get_legend().remove()\n",
    "    #same scale for all plots\n",
    "    axes[i//2, i%2].set_xlim(0.77, 0.94)\n",
    "    axes[i//2, i%2].set_ylim(0.8, 0.94)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intra Self-BLEU vs Intra similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 subplots one for each dataset in mean_data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "for i, (dataset, data) in enumerate(mean_data.groupby('dataset')):\n",
    "    ax = axes[i//2, i%2]\n",
    "    sns.scatterplot(data=data, x='self_bleu_group_mean', y='intra-similarity_mean', hue='label', ax=ax)\n",
    "    ax.set_title(dataset)\n",
    "    ax.set_xlabel('intra-Self BLEU')\n",
    "    ax.set_ylabel('intra-similarity')\n",
    "        #make only a single legend\n",
    "    if i == 0:\n",
    "        axes[i//2, i%2].legend()\n",
    "    else:\n",
    "        axes[i//2, i%2].get_legend().remove()\n",
    "    #same scale for all plots\n",
    "    axes[i//2, i%2].set_xlim(0, 0.25)\n",
    "    axes[i//2, i%2].set_ylim(0.75, 0.94)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = 'Set2'\n",
    "ort = 'h'\n",
    "\n",
    "metrics = [\"inter-similarity\", \"intra-similarity\", 'self_bleu', \"self_bleu_group\"]\n",
    "models_list = [\"ChatGPT Balanced\",'ChatGPT Proportional', 'GPT-4 Proportional', 'GPT-4 Balanced']\n",
    "colors = sns.color_palette(pal, len(models_list))\n",
    "\n",
    "f, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i//2, i%2]\n",
    "    pt.half_violinplot( x=metric, y=\"dataset\", data = df, palette = pal, bw = .2, cut = 0.,\n",
    "    scale = \"area\", width = .6, inner = None, orient = ort, ax=ax)\n",
    "\n",
    "    ax=sns.stripplot(x=metric, y=\"dataset\", data = df, palette = pal, edgecolor = \"white\",\n",
    "    size = 3, jitter = 1, zorder = 0, orient = ort, ax=ax)\n",
    "\n",
    "    ax=sns.boxplot( x=metric, y=\"dataset\", data = df, color = \"black\", width = .15, zorder = 10,\\\n",
    "    showcaps = True, boxprops = {'facecolor':'none', \"zorder\":10},\\\n",
    "    showfliers=True, whiskerprops = {'linewidth':2, \"zorder\":10},\\\n",
    "    saturation = 1, orient = ort, ax=ax)\n",
    "    if 'similarity' in metric:\n",
    "        ax.set_xlim(0.6, 1)\n",
    "    ax.set_xlabel(metric)\n",
    "    if 'bleu' in metric:\n",
    "        ax.set_xlim(-0.025, 0.7)\n",
    "\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    #set x axis label color to white\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.set_xlabel(metric)\n",
    "    ax.set_ylabel('')\n",
    "    #set transparent background\n",
    "    ax.patch.set_alpha(0.5)\n",
    "\n",
    "#make a legend of models_list with white label text\n",
    "legend_elements = [lines.Line2D([0], [0], marker='o', color='w', label=model, markerfacecolor=color, markersize=15) for model, color in zip(models_list, colors)]\n",
    "\n",
    "#place legend centered below the plots\n",
    "leg = f.legend(handles=legend_elements, loc='lower center', ncol=4, fontsize=16, framealpha=0.5)\n",
    "for text in leg.get_texts():\n",
    "    text.set_color(\"white\")\n",
    "\n",
    "#reduce distance between legend and plots\n",
    "plt.subplots_adjust(bottom=0.075)\n",
    "\n",
    "axes[0][0].set_xlabel(\"Cosine similarity\", fontsize=16, color='w')\n",
    "axes[0][0].set_title('Inter-similarity', fontsize=24, color='w')\n",
    "axes[1][0].set_xlabel(\"BLEU\", fontsize=16, color='w')\n",
    "#axes[1][0].set_title('Intra-similarity', fontsize=20)\n",
    "axes[0][1].set_title('Intra-similarity', fontsize=24, color='w')\n",
    "axes[0][1].set_xlabel(\"Average cosine similarity\", fontsize=16, color='w')\n",
    "#axes[1][1].set_title('Self-BLEU', fontsize=20)\n",
    "axes[1][1].set_xlabel(\"Average BLEU\", fontsize=16, color='w')\n",
    "\n",
    "\n",
    "#remove distance between subplots\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.15)\n",
    "\n",
    "#plt.savefig('similarity_boxplots.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dataset').quantile(0.95)['self_bleu']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE of Crowdsourced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read ten dim features tsv file as numpy\n",
    "ten_dim_features = np.loadtxt('ten-dim_features_no_neutral.tsv', delimiter='\\t')\n",
    "\n",
    "\n",
    "sne = TSNE(n_components=2, perplexity=50, learning_rate=50, n_iter=20000, n_jobs=-1)\n",
    "print(sne.learning_rate)\n",
    "X_new = sne.fit_transform(ten_dim_features)\n",
    "print(sne.n_iter_)\n",
    "print(sne.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn scatterplot\n",
    "fig, ax = plt.subplots( figsize=(10, 10))\n",
    "\n",
    "colors = sns.color_palette('Set2', n_colors=8)\n",
    "color_label = ['Fun', 'Social Support', 'Conflict', 'Similarity/Identity', 'Knowledge', 'Power', 'Trust', 'Respect']\n",
    "colors_dict = dict(zip(color_label, colors))\n",
    "\n",
    "labs = np.loadtxt('ten-dim_labels_no_neutral.tsv', delimiter='\\t', dtype=str)\n",
    "sns.scatterplot(x=X_new[:,0], y=X_new[:,1], hue=labs[:,1], palette='Set2', legend='full', ax=ax)\n",
    "\n",
    "#rename legend labels to color_label\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, color_label, loc='upper center', bbox_to_anchor=(0.5, -0.01), ncol=4)\n",
    "#remove box around legend\n",
    "ax.get_legend().get_frame().set_linewidth(0.0)\n",
    "\n",
    "#create box from (-60,-45) to (-40,-15)\n",
    "rect = patches.Rectangle((-60,-45),20,30,linewidth=2,edgecolor=colors_dict['Fun'],facecolor='none')\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "#create box from (-35,-70) to (5,-5)\n",
    "rect = patches.Rectangle((-35,-70),40,65,linewidth=2,edgecolor=colors_dict['Social Support'],facecolor='none')\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "#create box from (-30,-50) to (0,-20)\n",
    "rect = patches.Rectangle((-30,-50),30,30,linewidth=2,edgecolor=colors_dict['Respect'],facecolor='none')\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "#create elipse with center (-20,20) and width 40 and height 80, rotated 45 degrees\n",
    "ellipse = patches.Ellipse((-25,25),40,100,linewidth=2,edgecolor=colors_dict['Knowledge'],facecolor='none', angle=-45)\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(ellipse)\n",
    "#create circle with center (25,25) and radius 20\n",
    "circle = patches.Circle((30,20),35,linewidth=2,edgecolor=colors_dict['Conflict'],facecolor='none')\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(circle)\n",
    "\n",
    "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "#remove ticklabels\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "#save plot with high dpi\n",
    "\n",
    "plt.savefig('tsne_clust.png', dpi = 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read ten dim features tsv file as numpy\n",
    "ten_dim_features = np.loadtxt('ten-dim_features.tsv', delimiter='\\t')\n",
    "\n",
    "\n",
    "sne = TSNE(n_components=2, perplexity=50, learning_rate=50, n_iter=30000, n_jobs=-1)\n",
    "print(sne.learning_rate)\n",
    "X_new = sne.fit_transform(ten_dim_features)\n",
    "print(sne.n_iter_)\n",
    "print(sne.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn scatterplot\n",
    "fig, ax = plt.subplots( figsize=(12, 12))\n",
    "color_label = ['Neutral', 'Fun', 'Social Support', 'Conflict', 'Similarity/Identity', 'Knowledge', 'Power', 'Trust', 'Respect']\n",
    "\n",
    "\n",
    "labs = np.loadtxt('ten-dim_labels.tsv', delimiter='\\t', dtype=str)\n",
    "sns.scatterplot(x=X_new[:,0], y=X_new[:,1], hue=labs[:,1], palette='colorblind', legend='full', ax=ax)\n",
    "#rename legend labels to color_label\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, color_label, loc='upper center', bbox_to_anchor=(0.5, -0.01), ncol=5, framealpha=0.0)\n",
    "#remove box around legend\n",
    "ax.get_legend().get_frame().set_linewidth(0.0)\n",
    "for text in ax.get_legend().get_texts():\n",
    "    text.set_color(\"white\")\n",
    "\n",
    "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "#remove ticklabels\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "#make background transparent\n",
    "ax.patch.set_alpha(0.0)\n",
    "#remove borders\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig('tsne_with_neutral_new.png', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn scatterplot\n",
    "fig, ax = plt.subplots( figsize=(12, 12))\n",
    "color_label = ['Fun', 'Social Support', 'Conflict', 'Similarity/Identity', 'Knowledge', 'Power', 'Trust', 'Respect']\n",
    "colors = sns.color_palette('colorblind', n_colors=9)[1:]\n",
    "\n",
    "labs = np.loadtxt('ten-dim_labels.tsv', delimiter='\\t', dtype=str)\n",
    "\n",
    "X_no_neutral = X_new[labs[:,1] != 'neutral']\n",
    "labs = labs[labs[:,1] != 'neutral']\n",
    "\n",
    "sns.scatterplot(x=X_no_neutral[:,0], y=X_no_neutral[:,1], hue=labs[:,1], palette=colors, legend='full', ax=ax)\n",
    "#rename legend labels to color_label\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, color_label, loc='upper center', bbox_to_anchor=(0.5, -0.01), ncol=5, framealpha=0.0)\n",
    "#remove box around legend\n",
    "ax.get_legend().get_frame().set_linewidth(0.0)\n",
    "for text in ax.get_legend().get_texts():\n",
    "    text.set_color(\"white\")\n",
    "\n",
    "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "#remove ticklabels\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.patch.set_alpha(0.0)\n",
    "#remove borders\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig('tsne_no_neutral.png', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read ten dim features tsv file as numpy\n",
    "ten_dim_features = np.loadtxt('ten-dim_features.tsv', delimiter='\\t')\n",
    "sne = TSNE(n_components=2, perplexity=30, learning_rate=50, n_iter=20000, n_jobs=-1)\n",
    "print(sne.learning_rate)\n",
    "X_30 = sne.fit_transform(ten_dim_features)\n",
    "print(sne.n_iter_)\n",
    "print(sne.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn scatterplot\n",
    "fig, ax = plt.subplots( figsize=(10, 10))\n",
    "\n",
    "labs = np.loadtxt('ten-dim_labels.tsv', delimiter='\\t', dtype=str)\n",
    "sns.scatterplot(x=X_30[:,0], y=X_30[:,1], hue=labs[:,1], palette='Set2', legend='full', ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE of ChatGPT balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read ten dim features tsv file as numpy\n",
    "ten_dim_features = np.loadtxt('ten-dim_augmented_features.tsv', delimiter='\\t')\n",
    "\n",
    "\n",
    "sne = TSNE(n_components=2, perplexity=50, learning_rate=50, n_iter=30000, n_jobs=-1)\n",
    "print(sne.learning_rate)\n",
    "X_new = sne.fit_transform(ten_dim_features)\n",
    "print(sne.n_iter_)\n",
    "print(sne.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn scatterplot\n",
    "fig, ax = plt.subplots( figsize=(12, 12))\n",
    "color_label = ['Respect', 'Knowledge', 'Fun', 'Similarity/Identity', 'Power', 'Trust','Social Support', 'Conflict', 'Neutral']\n",
    "labs = np.loadtxt('ten-dim_augmented_labels.tsv', delimiter='\\t', dtype=str)\n",
    "sns.scatterplot(x=X_new[:,0], y=X_new[:,1], hue=labs[:,1], palette='colorblind', legend='full', ax=ax)\n",
    "#rename legend labels to color_label\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, color_label, loc='upper center', bbox_to_anchor=(0.5, -0.01), ncol=5, framealpha=0.0)\n",
    "#remove box around legend\n",
    "ax.get_legend().get_frame().set_linewidth(0.0)\n",
    "for text in ax.get_legend().get_texts():\n",
    "    text.set_color(\"white\")\n",
    "\n",
    "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "#remove ticklabels\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "#make background transparent\n",
    "ax.patch.set_alpha(0.0)\n",
    "#remove borders\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig('tsne_augmented_with_neutral_new.png', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn scatterplot\n",
    "fig, ax = plt.subplots( figsize=(12, 12))\n",
    "color_label = ['Respect', 'Knowledge', 'Fun', 'Similarity/Identity', 'Power', 'Trust','Social Support', 'Conflict']\n",
    "#colors = sns.color_palette('colorblind', n_colors=10)[2:]\n",
    "\n",
    "labs = np.loadtxt('ten-dim_augmented_labels.tsv', delimiter='\\t', dtype=str)\n",
    "\n",
    "X_no_neutral = X_new[labs[:,1] != 'neutral']\n",
    "labs = labs[labs[:,1] != 'neutral']\n",
    "\n",
    "sns.scatterplot(x=X_no_neutral[:,0], y=X_no_neutral[:,1], hue=labs[:,1], palette='colorblind', legend='full', ax=ax)\n",
    "#rename legend labels to color_label\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, color_label, loc='upper center', bbox_to_anchor=(0.5, -0.01), ncol=5, framealpha=0.0)\n",
    "#remove box around legend\n",
    "ax.get_legend().get_frame().set_linewidth(0.0)\n",
    "for text in ax.get_legend().get_texts():\n",
    "    text.set_color(\"white\")\n",
    "\n",
    "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "#remove ticklabels\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.patch.set_alpha(0.0)\n",
    "#remove borders\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig('tsne_augmented_no_neutral.png', dpi = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crowdsourced Normal vs SetFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels = ['Conflict', 'Fun', 'Knowledge', 'Neutral', 'Power', 'Respect', 'Similarity/Identity', 'Social Support', 'Trust' ]\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for filename in os.listdir():\n",
    "    if \"crowdsourced\" in filename:\n",
    "    #if 'gpt-3' in filename and \"e5\" in filename:\n",
    "        data = pd.read_json( filename, orient='records')\n",
    "        data['dataset'] = \".\".join(filename.split('.')[:-1])\n",
    "        df_list.append(data)\n",
    "\n",
    "#plot 2 subplots:\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    if i == 0:\n",
    "        cmap = 'Blues'\n",
    "        axs[i].set_title('Crowdsourced Normal', fontsize=20)\n",
    "    else:\n",
    "        cmap = 'Reds'\n",
    "        axs[i].set_title('Crowdsourced SetFit', fontsize=20)\n",
    "        \n",
    "    ConfusionMatrixDisplay.from_predictions(df.targets_labels, df.preds_labels, cmap=cmap,\n",
    "        xticks_rotation='vertical', ax=axs[i],  colorbar=True, normalize=None)\n",
    "    \n",
    "    axs[i].set_xticklabels(plot_labels, fontsize=14)\n",
    "    axs[i].set_xlabel('Predicted label', fontsize=16)\n",
    "    if i ==1:\n",
    "        axs[i].set_ylabel('')\n",
    "        axs[i].set_yticks([])\n",
    "        \n",
    "axs[0].set_yticklabels(plot_labels, fontsize=14)\n",
    "axs[0].set_ylabel('True label', fontsize=16)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.01, hspace=0)\n",
    "\n",
    "#plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "plt.savefig('classification_results/conf_mat_crowd.png', dpi = 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatGPT balanced Setfit vs ChatGPT balanced + Crowdsourced Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for filename in os.listdir():\n",
    "    if 'gpt-3' in filename and \"e5\" in filename:\n",
    "        data = pd.read_json( filename, orient='records')\n",
    "        data['dataset'] = \".\".join(filename.split('.')[:-1])\n",
    "        df_list.append(data)\n",
    "\n",
    "#plot 2 subplots:\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    if i == 0:\n",
    "        cmap = 'Blues'\n",
    "        axs[i].set_title('ChatGPT balanced + C (Normal)', fontsize=20)\n",
    "    else:\n",
    "        cmap = 'Reds'\n",
    "        axs[i].set_title('ChatGPT balanced (SetFit)', fontsize=20)\n",
    "        \n",
    "    ConfusionMatrixDisplay.from_predictions(df.targets_labels, df.preds_labels, cmap=cmap,\n",
    "        xticks_rotation='vertical', ax=axs[i],  colorbar=True, normalize=None)\n",
    "    axs[i].set_xticklabels(plot_labels, fontsize=14)\n",
    "    axs[i].set_xlabel('Predicted label', fontsize=16)\n",
    "    if i ==1:\n",
    "        axs[i].set_ylabel('')\n",
    "        axs[i].set_yticks([])\n",
    "        \n",
    "axs[0].set_yticklabels(plot_labels, fontsize=14)\n",
    "axs[0].set_ylabel('True label', fontsize=16)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.01, hspace=0)\n",
    "\n",
    "plt.savefig('classification_results/conf_mat_chatGPT.png', dpi = 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir() if file.startswith('sentiment')]\n",
    "labels: List[str] = [\n",
    "            \"negative\",\n",
    "            \"neutral\",\n",
    "            \"positive\",\n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"label\", \"similarity\", \"dataset\"])\n",
    "\n",
    "for filename in files:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    similarities_concatenated = {k: [] for k in labels}\n",
    "    for label, dict_with_similarities in data.items():\n",
    "        for text in dict_with_similarities:\n",
    "            list_similarities = [x[0] for x in dict_with_similarities[text]]\n",
    "            similarities_concatenated[label].extend(list_similarities)\n",
    "\n",
    "    for label, similarities in similarities_concatenated.items():\n",
    "        df = df.append(pd.DataFrame({\"label\": [label] * len(similarities), \"similarity\": similarities, \"dataset\": [filename.split('_augmented_similarity.json')[0]] * len(similarities)}))\n",
    "\n",
    "# set figure size\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "sns.boxplot(data=df, x=\"similarity\", y=\"label\", hue=\"dataset\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hate-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir() if file.startswith('hate-speech')]\n",
    "labels: List[str] = [\"NOT\", \"OFF\"]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"label\", \"similarity\", \"dataset\"])\n",
    "\n",
    "for filename in files:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    similarities_concatenated = {k: [] for k in labels}\n",
    "    for label, dict_with_similarities in data.items():\n",
    "        for text in dict_with_similarities:\n",
    "            list_similarities = [x[0] for x in dict_with_similarities[text]]\n",
    "            similarities_concatenated[label].extend(list_similarities)\n",
    "\n",
    "    for label, similarities in similarities_concatenated.items():\n",
    "        df = df.append(pd.DataFrame({\"label\": [label] * len(similarities), \"similarity\": similarities, \"dataset\": [filename.split('_augmented_similarity.json')[0]] * len(similarities)}))\n",
    "\n",
    "# set figure size\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "sns.boxplot(data=df, x=\"similarity\", y=\"label\", hue=\"dataset\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_in_prod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
